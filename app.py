import streamlit as st
import os
from moviepy.editor import VideoFileClip, concatenate_videoclips
import speech_recognition as sr
import numpy as np
import matplotlib.pyplot as plt
from pydub import AudioSegment
import tempfile
import time

# ×”×’×“×¨×•×ª ×¨××©×•× ×™×•×ª
st.set_page_config(layout="wide", page_title="×¢×•×¨×š ×¤×•×“×§××¡×˜×™× ×—×›×", page_icon="ğŸ¤")
st.title("ğŸ¤ ×¤×•×“×§××¡×˜/×”×¨×¦××” ×œ×¢×¨×™×›×ª ×¡×¨×˜×•× ×™× ××•×˜×•××˜×™×ª")
st.subheader("×”×¢×œ×” ×§×•×‘×¥, ×‘×—×¨ ×§×˜×¢×™× ××¢× ×™×™× ×™× ×•×¦×•×¨ ×¡×¨×˜×•×Ÿ ××•×ª×× ××™×©×™×ª")

# ×¤×•× ×§×¦×™×•×ª ×¢×–×¨
def extract_audio(video_path):
    """×—×™×œ×•×¥ ××•×“×™×• ××”×•×™×“××•"""
    try:
        video = VideoFileClip(video_path)
        audio = video.audio
        audio_path = "temp_audio.wav"
        audio.write_audiofile(audio_path, logger=None)
        return audio_path
    except Exception as e:
        st.error(f"×©×’×™××” ×‘×—×™×œ×•×¥ ××•×“×™×•: {str(e)}")
        return None

def find_highlights(audio_path, num_segments=5, energy_threshold=0.7):
    """×–×™×”×•×™ ×§×˜×¢×™× ××¢× ×™×™× ×™× ×œ×¤×™ ×× ×¨×’×™×™×ª ×§×•×œ"""
    try:
        audio = AudioSegment.from_wav(audio_path)
        
        # ×—×™×©×•×‘ ×× ×¨×’×™×™×ª ××•×“×™×•
        energy = []
        window_size = 1000  # 1 ×©× ×™×™×”
        for i in range(0, len(audio), window_size):
            segment = audio[i:i+window_size]
            energy.append(segment.rms)
        
        # × ×¨××•×œ ×”×× ×¨×’×™×”
        energy = np.array(energy)
        energy_normalized = (energy - energy.min()) / (energy.max() - energy.min())
        
        # ××¦×™××ª × ×§×•×“×•×ª ×©×™× ××¢×œ ×¡×£ ××¡×•×™×
        peaks = []
        for i in range(len(energy_normalized)):
            if energy_normalized[i] > energy_threshold:
                # ×•×™×“×•× ×©×”×¤×™×§ ×œ× ×§×¨×•×‘ ××“×™ ×œ×¤×™×§ ×§×•×“×
                if not peaks or i - peaks[-1] > 30:  # ×œ×¤×—×•×ª 30 ×©× ×™×•×ª ×”×¤×¨×©
                    peaks.append(i)
        
        # ×× ×œ× ××¦×× ×• ××¡×¤×™×§ ×¤×™×§×™×, × ×•×¨×™×“ ××ª ×”×¡×£
        if len(peaks) < num_segments:
            peaks = np.argsort(energy)[-num_segments:]
        
        return sorted(peaks[:num_segments])
    except Exception as e:
        st.error(f"×©×’×™××” ×‘×–×™×”×•×™ ×§×˜×¢×™×: {str(e)}")
        return []

def create_clip(video_path, start_time, duration=30):
    """×™×¦×™×¨×ª ×§×˜×¢ ×•×™×“××•"""
    try:
        video = VideoFileClip(video_path)
        start = max(0, start_time - duration//2)
        end = min(start + duration, video.duration)
        
        # ×”×ª×××ª ×–×× ×™ ×”×”×ª×—×œ×” ×•×”×¡×™×•×
        if end - start < duration and end < video.duration:
            end = min(video.duration, start + duration)
        if end - start < duration and start > 0:
            start = max(0, end - duration)
            
        return video.subclip(start, end)
    except Exception as e:
        st.error(f"×©×’×™××” ×‘×™×¦×™×¨×ª ×§×˜×¢: {str(e)}")
        return None

def save_video(clip, filename):
    """×©××™×¨×ª ×•×™×“××•"""
    try:
        clip.write_videofile(filename, codec='libx264', audio_codec='aac', logger=None)
        return True
    except Exception as e:
        st.error(f"×©×’×™××” ×‘×©××™×¨×ª ×•×™×“××•: {str(e)}")
        return False

def visualize_audio_energy(audio_path):
    """×™×¦×™×¨×ª ×•×™×–×•××œ×™×–×¦×™×” ×©×œ ×× ×¨×’×™×™×ª ×”××•×“×™×•"""
    try:
        audio = AudioSegment.from_wav(audio_path)
        
        # ×—×™×©×•×‘ ×× ×¨×’×™×”
        energy = []
        window_size = 1000
        for i in range(0, len(audio), window_size):
            segment = audio[i:i+window_size]
            energy.append(segment.rms)
        
        # ×™×¦×™×¨×ª ×’×¨×£
        fig, ax = plt.subplots(figsize=(12, 4))
        time_axis = np.arange(len(energy))
        ax.plot(time_axis, energy)
        ax.set_xlabel('×–××Ÿ (×©× ×™×•×ª)')
        ax.set_ylabel('×¢×•×¦××ª ×§×•×œ')
        ax.set_title('× ×™×ª×•×— ×× ×¨×’×™×™×ª ××•×“×™×•')
        ax.grid(True, alpha=0.3)
        
        return fig
    except Exception as e:
        st.error(f"×©×’×™××” ×‘×™×¦×™×¨×ª ×•×™×–×•××œ×™×–×¦×™×”: {str(e)}")
        return None

# ×××©×§ ××©×ª××©
col1, col2 = st.columns([2, 1])

with col1:
    uploaded_file = st.file_uploader("×”×¢×œ×” ×§×•×‘×¥ ×•×™×“××• ××• ××•×“×™×•", type=["mp4", "avi", "mov", "mp3", "wav"])

with col2:
    st.markdown("### ×”×’×“×¨×•×ª")
    num_segments = st.slider("××¡×¤×¨ ×§×˜×¢×™× ×œ×–×™×”×•×™", min_value=3, max_value=10, value=5)
    clip_duration = st.slider("××•×¨×š ×›×œ ×§×˜×¢ (×©× ×™×•×ª)", min_value=15, max_value=60, value=30)
    energy_threshold = st.slider("×¨×’×™×©×•×ª ×–×™×”×•×™", min_value=0.5, max_value=0.9, value=0.7)

if uploaded_file:
    # ×™×¦×™×¨×ª ××§×•× ×œ×§×‘×¦×™× ×–×× ×™×™×
    if 'temp_dir' not in st.session_state:
        st.session_state.temp_dir = tempfile.mkdtemp()
    
    # ×©××™×¨×ª ×§×•×‘×¥ ×–×× ×™
    with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1], dir=st.session_state.temp_dir) as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        file_path = tmp_file.name
    
    # ×—×™×œ×•×¥ ××•×“×™×•
    with st.spinner('ğŸµ ××—×œ×¥ ××•×“×™×•...'):
        if file_path.endswith(('.mp4', '.avi', '.mov')):
            audio_path = extract_audio(file_path)
            video_clip = VideoFileClip(file_path)
            st.success(f"××•×¨×š ×”×•×™×“××•: {int(video_clip.duration//60)}:{int(video_clip.duration%60):02d} ×“×§×•×ª")
        else:
            audio_path = file_path
            video_clip = None
            audio = AudioSegment.from_file(file_path)
            st.success(f"××•×¨×š ×”××•×“×™×•: {int(len(audio)//60000)}:{int((len(audio)%60000)//1000):02d} ×“×§×•×ª")
    
    # ×”×¦×’×ª ×•×™×–×•××œ×™×–×¦×™×”
    if audio_path:
        st.subheader("ğŸ“Š × ×™×ª×•×— ××•×“×™×•")
        fig = visualize_audio_energy(audio_path)
        if fig:
            st.pyplot(fig)
    
    # ×–×™×”×•×™ ×§×˜×¢×™× ××¢× ×™×™× ×™×
    with st.spinner('ğŸ” ××—×¤×© ×§×˜×¢×™× ××¢× ×™×™× ×™×...'):
        highlights = find_highlights(audio_path, num_segments, energy_threshold)
    
    if highlights:
        st.success(f"××¦×× ×• {len(highlights)} ×§×˜×¢×™× ××¢× ×™×™× ×™×!")
        
        # ×™×¦×™×¨×ª ×§×˜×¢×™ ×•×™×“××•
        clips = []
        clip_paths = []
        
        if video_clip:
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i, peak in enumerate(highlights):
                status_text.text(f'×™×•×¦×¨ ×§×˜×¢ {i+1} ××ª×•×š {len(highlights)}...')
                clip = create_clip(file_path, peak, clip_duration)
                if clip:
                    clip_path = os.path.join(st.session_state.temp_dir, f"clip_{i}.mp4")
                    if save_video(clip, clip_path):
                        clips.append(clip)
                        clip_paths.append(clip_path)
                progress_bar.progress((i+1)/len(highlights))
            
            progress_bar.empty()
            status_text.empty()
        
        # ×”×¦×’×ª ×”×§×˜×¢×™×
        if clip_paths:
            st.subheader("ğŸ¬ ×§×˜×¢×™× ××•××œ×¦×™×:")
            selected_clips = []
            
            # ×™×¦×™×¨×ª ×¨×©×ª ×©×œ ×§×˜×¢×™×
            cols_per_row = 3
            for i in range(0, len(clip_paths), cols_per_row):
                cols = st.columns(cols_per_row)
                for j in range(min(cols_per_row, len(clip_paths) - i)):
                    idx = i + j
                    with cols[j]:
                        st.markdown(f"**×§×˜×¢ {idx+1}** (×“×§×” {highlights[idx]//60}:{highlights[idx]%60:02d})")
                        st.video(clip_paths[idx])
                        if st.checkbox(f"×›×œ×•×œ ×§×˜×¢ {idx+1}", key=f"clip_{idx}", value=True):
                            selected_clips.append(idx)
            
            # ×™×¦×™×¨×ª ×¡×¨×˜×•×Ÿ ×—×“×©
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                if selected_clips and st.button("ğŸ¬ ×¦×•×¨ ×¡×¨×˜×•×Ÿ ××—×•×‘×¨", type="primary", use_container_width=True):
                    with st.spinner('ğŸï¸ ××¨×›×™×‘ ××ª ×”×¡×¨×˜×•×Ÿ ×”×¡×•×¤×™...'):
                        try:
                            # ×‘×—×™×¨×ª ×”×§×œ×™×¤×™× ×©× ×‘×—×¨×•
                            final_clips = [clips[i] for i in selected_clips]
                            
                            # ×—×™×‘×•×¨ ×”×§×œ×™×¤×™×
                            final_video = concatenate_videoclips(final_clips, method="compose")
                            
                            # ×©××™×¨×ª ×”×¡×¨×˜×•×Ÿ ×”×¡×•×¤×™
                            output_path = os.path.join(st.session_state.temp_dir, "final_video.mp4")
                            save_video(final_video, output_path)
                            
                            st.success("âœ… ×”×¡×¨×˜×•×Ÿ ×”×•×¨×›×‘ ×‘×”×¦×œ×—×”!")
                            st.video(output_path)
                            
                            # ×›×¤×ª×•×¨ ×”×•×¨×“×”
                            with open(output_path, "rb") as f:
                                st.download_button(
                                    "â¬‡ï¸ ×”×•×¨×“ ×¡×¨×˜×•×Ÿ ×¡×•×¤×™",
                                    f,
                                    file_name=f"highlights_{int(time.time())}.mp4",
                                    mime="video/mp4",
                                    use_container_width=True
                                )
                        except Exception as e:
                            st.error(f"×©×’×™××” ×‘×”×¨×›×‘×ª ×”×¡×¨×˜×•×Ÿ: {str(e)}")
    else:
        st.warning("×œ× × ××¦××• ×§×˜×¢×™× ××¢× ×™×™× ×™×. × ×¡×” ×œ×©× ×•×ª ××ª ×”×’×“×¨×•×ª ×”×¨×’×™×©×•×ª.")

# ×”×¡×‘×¨ ×¢×œ ×”××¢×¨×›×ª
with st.sidebar:
    st.markdown("## ğŸ› ï¸ ××™×š ×–×” ×¢×•×‘×“?")
    st.markdown("""
    1. **×”×¢×œ×” ×§×•×‘×¥** - ×•×™×“××• ××• ××•×“×™×•
    2. **× ×™×ª×•×— ××•×˜×•××˜×™** - ×”××¢×¨×›×ª ××–×”×” ×§×˜×¢×™× ×¢× ×× ×¨×’×™×” ×’×‘×•×”×”
    3. **×‘×—×™×¨×” ×™×“× ×™×ª** - ×¦×¤×” ×•×¡××Ÿ ×§×˜×¢×™× ×¨×¦×•×™×™×
    4. **×™×¦×™×¨×ª ×¡×¨×˜×•×Ÿ** - ×—×™×‘×•×¨ ×”×§×˜×¢×™× ×œ×¡×¨×˜×•×Ÿ ××—×“
    5. **×”×•×¨×“×”** - ×©××•×¨ ××ª ×”×ª×•×¦××” ×”×¡×•×¤×™×ª
    """)
    
    st.markdown("## âš™ï¸ ×˜×›× ×•×œ×•×’×™×•×ª ×‘×©×™××•×©")
    st.markdown("""
    - **Streamlit** - ×××©×§ ××©×ª××© ××™× ×˜×¨××§×˜×™×‘×™
    - **MoviePy** - ×¢×¨×™×›×ª ×•×™×“××• ××ª×§×“××ª
    - **PyDub** - × ×™×ª×•×— ×•×¢×™×‘×•×“ ××•×“×™×•
    - **NumPy** - ×—×™×©×•×‘×™× ××ª××˜×™×™×
    - **Matplotlib** - ×•×™×–×•××œ×™×–×¦×™×•×ª
    """)
    
    st.markdown("## ğŸ“‹ ××’×‘×œ×•×ª ×•×“×¨×™×©×•×ª")
    st.markdown("""
    - ×’×•×“×œ ×§×•×‘×¥ ××§×¡×™××œ×™: 200MB
    - ×¤×•×¨××˜×™× × ×ª××›×™×: MP4, AVI, MOV, MP3, WAV
    - × ×“×¨×© ×—×™×‘×•×¨ ××™× ×˜×¨× ×˜ ×™×¦×™×‘
    - ×–××Ÿ ×¢×™×‘×•×“ ×ª×œ×•×™ ×‘××•×¨×š ×”×§×•×‘×¥
    """)
    
    st.markdown("## ğŸ’¡ ×˜×™×¤×™× ×œ×ª×•×¦××•×ª ×˜×•×‘×•×ª")
    st.markdown("""
    - ×”×©×ª××© ×‘×§×‘×¦×™× ×‘××™×›×•×ª ×˜×•×‘×”
    - ×”×ª×× ××ª ×¨×’×™×©×•×ª ×”×–×™×”×•×™ ×œ×¡×•×’ ×”×ª×•×›×Ÿ
    - ×‘×“×•×§ ×›×œ ×§×˜×¢ ×œ×¤× ×™ ×”×›×œ×œ×ª×•
    - ×©××•×¨ ×¢×œ ×§×˜×¢×™× ×§×¦×¨×™× ×•×“×™× ××™×™×
    """)

# × ×™×§×•×™ ×§×‘×¦×™× ×–×× ×™×™× ×‘×¡×™×•×
if st.button("ğŸ—‘ï¸ × ×§×” ×§×‘×¦×™× ×–×× ×™×™×", help="×œ×—×¥ ×œ× ×™×§×•×™ ×›×œ ×”×§×‘×¦×™× ×”×–×× ×™×™×"):
    if 'temp_dir' in st.session_state and os.path.exists(st.session_state.temp_dir):
        import shutil
        shutil.rmtree(st.session_state.temp_dir)
        del st.session_state.temp_dir
        st.success("×§×‘×¦×™× ×–×× ×™×™× × ×•×§×• ×‘×”×¦×œ×—×”!")
        st.experimental_rerun()
